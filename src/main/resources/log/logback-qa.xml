<?xml version="1.0" encoding="UTF-8"?>

<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <contextName>qypms</contextName>
    <include resource="org/springframework/boot/logging/logback/base.xml"/>
    <!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径-->
    <!--<property name="LOG_HOME" value="/home" />-->
    <!-- 开发环境变量develop-->
    <springProfile name="dev">
<!--         <property name="LOG_HOME" value="D:/Works/JavaWebWork/qypms-boot/log"/> -->
        <property name="LOG_HOME" value="c:log.log"/>
    </springProfile>
    <!-- 生成环境变量product-->
    <springProfile name="prod">
        <property name="LOG_HOME" value="logs"/>
    </springProfile>
    <!--qa环境变量product-->
    <springProfile name="docker">
        <property name="LOG_HOME" value="logs"/>
    </springProfile>
    <!-- 生成环境变量product-->
    <springProfile name="test">
        <property name="LOG_HOME" value="/var/fangqian/yunding/logs"/>
    </springProfile>
    <!-- 生成环境变量product-->
    <springProfile name="pre">
        <property name="LOG_HOME" value="logs"/>
    </springProfile>
    <!-- 控制台输出 -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
        </encoder>
    </appender>
    <!-- 日志文件:按照每天生成 -->
    <!--<appender name="DEBUG"  class="ch.qos.logback.core.rolling.RollingFileAppender">-->
    <!--<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">-->
    <!--&lt;!&ndash;日志文件输出的文件地址和名称&ndash;&gt;-->
    <!--<FileNamePattern>${LOG_HOME}/qypmsBoot_debug_%d{yyyy-MM-dd}.log</FileNamePattern>-->
    <!--&lt;!&ndash;日志文件保留天数&ndash;&gt;-->
    <!--<MaxHistory>30</MaxHistory>-->
    <!--</rollingPolicy>-->
    <!--<encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">-->
    <!--<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>-->
    <!--</encoder>-->
    <!--&lt;!&ndash;日志文件最大的大小&ndash;&gt;-->
    <!--<triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">-->
    <!--<MaxFileSize>10MB</MaxFileSize>-->
    <!--</triggeringPolicy>-->
    <!--<filter class="ch.qos.logback.classic.filter.LevelFilter">-->
    <!--<level>DEBUG</level>-->
    <!--<onMatch>ACCEPT</onMatch>-->
    <!--<onMismatch>DENY</onMismatch>-->
    <!--</filter>-->
    <!--</appender>-->
    <!--<appender name="INFO"  class="ch.qos.logback.core.rolling.RollingFileAppender">-->
    <!--<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">-->
    <!--&lt;!&ndash;日志文件输出的文件地址和名称&ndash;&gt;-->
    <!--<FileNamePattern>${LOG_HOME}/qypmsBoot_info_%d{yyyy-MM-dd}.log</FileNamePattern>-->
    <!--&lt;!&ndash;日志文件保留天数&ndash;&gt;-->
    <!--<MaxHistory>30</MaxHistory>-->
    <!--</rollingPolicy>-->
    <!--<encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">-->
    <!--<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>-->
    <!--</encoder>-->
    <!--&lt;!&ndash;日志文件最大的大小&ndash;&gt;-->
    <!--<triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">-->
    <!--<MaxFileSize>10MB</MaxFileSize>-->
    <!--</triggeringPolicy>-->
    <!--<filter class="ch.qos.logback.classic.filter.LevelFilter">-->
    <!--<level>INFO</level>-->
    <!--<onMatch>ACCEPT</onMatch>-->
    <!--<onMismatch>DENY</onMismatch>-->
    <!--</filter>-->
    <!--</appender>-->
    <appender name="ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!--日志文件输出的文件地址和名称-->
            <FileNamePattern>${LOG_HOME}/qypmsBoot_error_%d{yyyy-MM-dd}.log</FileNamePattern>
            <!--日志文件保留天数-->
            <MaxHistory>30</MaxHistory>
        </rollingPolicy>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
        </encoder>
        <!--日志文件最大的大小-->
        <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <MaxFileSize>10MB</MaxFileSize>
        </triggeringPolicy>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <appender name="stash" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>192.168.2.62:5000</destination>

        <encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
            <providers>
                <mdc/> <!-- MDC variables on the Thread will be written as JSON fields-->
                <context/> <!--Outputs entries from logback's context -->
                <version/> <!-- Logstash json format version, the @version field in the output-->
                <logLevel/>
                <loggerName/>

                <pattern>
                    <pattern>
                        {
                        <!-- we can add some custom fields to be sent with all the log entries.-->
                        <!--make filtering easier in Logstash-->
                        "appName": "saas4.0",
                        "appVersion": "1.0"
                        }
                    </pattern>
                </pattern>

                <threadName/>
                <message/>

                <logstashMarkers/> <!-- Useful so we can add extra information for specific log lines as Markers-->
                <arguments/> <!--or through StructuredArguments-->

                <stackTrace/>
            </providers>
        </encoder>
    </appender>


    <!-- 日志输出级别 -->
    <!-- logback为java中的包 -->
    <logger name="com.odfly" level="DEBUG">
        <!--<appender-ref ref="DEBUG" />-->
        <appender-ref ref="ERROR"/>
        <appender-ref ref="stash"/>
        <!--<appender-ref ref="INFO" />-->
    </logger>
    <logger name="com.odfly.task.api.server.HouseSolrServer" level="ERROR" />
    <logger name="com.odfly.task.HouseSolr" level="ERROR" />
    <logger name="com.odfly.module.house.service.HouseService" level="ERROR" />
    <logger name="com.odfly.module.house.dao.HouseMapper" level="ERROR" />
    <!--<root level="INFO">-->
    <!--<appender-ref ref="STDOUT" />-->
    <!--</root>-->
</configuration>